"""Tokenç»Ÿè®¡ç®¡ç†"""

import asyncio
import json
import os
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any

from .constants import STATS_FILE, DAILY_STATS_FILE


class TokenStatsManager:
    """Tokenç»Ÿè®¡ç®¡ç†å™¨"""
    
    CHARS_PER_TOKEN_EN = 4.0
    CHARS_PER_TOKEN_ZH = 1.5
    
    def __init__(self, filepath=STATS_FILE, daily_filepath=DAILY_STATS_FILE):
        self.filepath = filepath
        self.daily_filepath = daily_filepath
        self.stats = {"total_requests": 0, "total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0}
        self.daily_stats = {
            "date": "",
            "reset_time": "",
            "models": {}
        }
        self.lock = asyncio.Lock()
        # å½“å‰è¯·æ±‚çš„tokenè®¡æ•°ï¼ˆç”¨äºæµå¼å“åº”ï¼‰
        self._current_prompt_tokens = 0
        self._current_completion_tokens = 0
        
        self.load_stats()
        self.load_daily_stats()
        
        # åˆå§‹åŒ–æˆ–æ£€æŸ¥æ¯æ—¥ç»Ÿè®¡æ˜¯å¦éœ€è¦é‡ç½®
        self._check_and_reset_daily_stats()

    def load_stats(self):
        try:
            with open(self.filepath, 'r', encoding='utf-8') as f:
                self.stats = json.load(f)
        except FileNotFoundError:
            self.save_stats()
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç»Ÿè®¡å¤±è´¥: {e}")

    def save_stats(self):
        try:
            with open(self.filepath, 'w', encoding='utf-8') as f:
                json.dump(self.stats, f, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç»Ÿè®¡å¤±è´¥: {e}")

    def load_daily_stats(self):
        try:
            with open(self.daily_filepath, 'r', encoding='utf-8') as f:
                self.daily_stats = json.load(f)
        except FileNotFoundError:
            self._reset_daily_stats_structure()
            self.save_daily_stats()
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")
            self._reset_daily_stats_structure()

    def save_daily_stats(self):
        try:
            with open(self.daily_filepath, 'w', encoding='utf-8') as f:
                json.dump(self.daily_stats, f, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ¯æ—¥ç»Ÿè®¡å¤±è´¥: {e}")

    def _get_beijing_time(self) -> datetime:
        """è·å–åŒ—äº¬æ—¶é—´"""
        utc_now = datetime.now(timezone.utc)
        beijing_tz = timezone(timedelta(hours=8))
        return utc_now.astimezone(beijing_tz)

    def _reset_daily_stats_structure(self):
        """é‡ç½®æ¯æ—¥ç»Ÿè®¡ç»“æ„"""
        now = self._get_beijing_time()
        # è®¡ç®—ä¸‹ä¸€ä¸ª0ç‚¹
        next_reset = (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
        
        self.daily_stats = {
            "date": now.strftime("%Y-%m-%d"),
            "reset_time": next_reset.isoformat(),
            "models": {}
        }

    def _check_and_reset_daily_stats(self):
        """æ£€æŸ¥å¹¶é‡ç½®æ¯æ—¥ç»Ÿè®¡"""
        now = self._get_beijing_time()
        current_date = now.strftime("%Y-%m-%d")
        
        if self.daily_stats.get("date") != current_date:
            print(f"ğŸ”„ é‡ç½®æ¯æ—¥ç»Ÿè®¡: {self.daily_stats.get('date')} -> {current_date}")
            self._reset_daily_stats_structure()
            self.save_daily_stats()

    def estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—tokenæ•°é‡"""
        if not text:
            return 0
        
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        non_chinese_chars = len(text) - chinese_chars
        
        chinese_tokens = chinese_chars / self.CHARS_PER_TOKEN_ZH
        non_chinese_tokens = non_chinese_chars / self.CHARS_PER_TOKEN_EN
        
        return max(1, int(chinese_tokens + non_chinese_tokens))
    
    def estimate_messages_tokens(self, messages: List[Dict]) -> int:
        """ä¼°ç®—æ¶ˆæ¯åˆ—è¡¨çš„tokenæ•°"""
        total = 0
        for msg in messages:
            total += 4
            content = msg.get('content', '')
            if isinstance(content, str):
                total += self.estimate_tokens(content)
            elif isinstance(content, list):
                for part in content:
                    if part.get('type') == 'text':
                        total += self.estimate_tokens(part.get('text', ''))
                    elif part.get('type') == 'image_url':
                        total += 765
        return total

    async def update(self, prompt_tokens: int, completion_tokens: int, model: str = "unknown", success: bool = True):
        """æ›´æ–°ç»Ÿè®¡æ•°æ®"""
        async with self.lock:
            # 1. æ›´æ–°æ€»ä½“ç»Ÿè®¡
            self.stats["total_requests"] += 1
            self.stats["prompt_tokens"] += prompt_tokens
            self.stats["completion_tokens"] += completion_tokens
            self.stats["total_tokens"] += (prompt_tokens + completion_tokens)
            self.save_stats()
            
            # 2. æ›´æ–°æ¯æ—¥ç»Ÿè®¡
            self._check_and_reset_daily_stats()
            
            if model not in self.daily_stats["models"]:
                self.daily_stats["models"][model] = {
                    "total_requests": 0,
                    "success_requests": 0,
                    "failed_requests": 0,
                    "total_tokens": 0,
                    "prompt_tokens": 0,
                    "completion_tokens": 0
                }
            
            model_stats = self.daily_stats["models"][model]
            model_stats["total_requests"] += 1
            if success:
                model_stats["success_requests"] += 1
            else:
                model_stats["failed_requests"] += 1
                
            model_stats["prompt_tokens"] += prompt_tokens
            model_stats["completion_tokens"] += completion_tokens
            model_stats["total_tokens"] += (prompt_tokens + completion_tokens)
            
            self.save_daily_stats()
    
    def set_current_request_tokens(self, prompt_tokens: int = 0, completion_tokens: int = 0):
        self._current_prompt_tokens = prompt_tokens
        self._current_completion_tokens = completion_tokens
    
    def get_current_usage(self) -> Dict[str, int]:
        return {
            "prompt_tokens": self._current_prompt_tokens,
            "completion_tokens": self._current_completion_tokens,
            "total_tokens": self._current_prompt_tokens + self._current_completion_tokens
        }
    
    def get_daily_stats(self) -> Dict[str, Any]:
        """è·å–æ¯æ—¥ç»Ÿè®¡æ•°æ®"""
        self._check_and_reset_daily_stats()
        return self.daily_stats
        
    def get_total_stats(self) -> Dict[str, Any]:
        """è·å–æ€»ä½“ç»Ÿè®¡æ•°æ®"""
        return self.stats
    
    def print_summary(self):
        print(f"ğŸ“Š ç´¯è®¡ç»Ÿè®¡: è¯·æ±‚={self.stats['total_requests']}, Token={self.stats['total_tokens']} (P:{self.stats['prompt_tokens']} C:{self.stats['completion_tokens']})")